{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Setup"
      ],
      "metadata": {
        "id": "WcNYdN6dKWmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "anasmohammedtahir_covidqu_path = kagglehub.dataset_download('anasmohammedtahir/covidqu')"
      ],
      "metadata": {
        "id": "4rbiqYEFNpQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0071f9a-9a79-4829-e0e3-a5c2de7f806d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'covidqu' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "src = anasmohammedtahir_covidqu_path\n",
        "dst = \"/content/covidqu\"\n",
        "\n",
        "if not os.path.exists(dst):\n",
        "    shutil.copytree(src, dst)"
      ],
      "metadata": {
        "id": "3UiXvC8hNpu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q segmentation-models-pytorch albumentations opencv-python scikit-image"
      ],
      "metadata": {
        "id": "DTUNbY0jNtxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3034cd51-789f-416b-ffa0-3b6082806dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Requirement"
      ],
      "metadata": {
        "id": "4f0sklAEJZFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZYOimDmMeUD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import KFold\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import segmentation_models_pytorch as smp\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "torch.manual_seed(3)\n",
        "np.random.seed(3)\n",
        "\n",
        "config = {\n",
        "    'data_root': '/content/covidqu/Infection Segmentation Data/Infection Segmentation Data',\n",
        "\n",
        "    'image_size': 256, #384,\n",
        "    'batch_size': 8,\n",
        "    'num_epochs': 30,\n",
        "    'learning_rate': 3e-4,\n",
        "    'weight_decay': 1e-5,\n",
        "    'patience': 5,\n",
        "\n",
        "    'encoder_name': 'efficientnet-b3',\n",
        "    'encoder_weights': 'imagenet',\n",
        "    'architecture': 'UnetPlusPlus',\n",
        "    'loss_function': 'bce_dice',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Dataset"
      ],
      "metadata": {
        "id": "MWE0X3OYJedK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_categories(data_root, split='Train'):\n",
        "\n",
        "    categories = ['COVID-19', 'Non-COVID', 'Normal']\n",
        "    all_data = []\n",
        "\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(data_root, split, category)\n",
        "\n",
        "        images_path = os.path.join(category_path, 'images')\n",
        "        infection_masks_path = os.path.join(category_path, 'infection masks')\n",
        "        lung_masks_path = os.path.join(category_path, 'lung masks')\n",
        "\n",
        "        if not os.path.exists(images_path):\n",
        "            print(f\"  Warning: {images_path} does not exist, skipping...\")\n",
        "            continue\n",
        "\n",
        "        image_files = sorted([f for f in os.listdir(images_path) if f.endswith('.png')])\n",
        "\n",
        "        print(f\"  {category}: Found {len(image_files)} images\")\n",
        "\n",
        "        for img_file in image_files:\n",
        "            img_path = os.path.join(images_path, img_file)\n",
        "            infection_mask_path = os.path.join(infection_masks_path, img_file)\n",
        "            lung_mask_path = os.path.join(lung_masks_path, img_file)\n",
        "\n",
        "            if os.path.exists(infection_mask_path):\n",
        "                test_mask = cv2.imread(infection_mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if test_mask is not None:\n",
        "                    all_data.append({\n",
        "                        'image_path': img_path,\n",
        "                        'infection_mask_path': infection_mask_path,\n",
        "                        'lung_mask_path': lung_mask_path if os.path.exists(lung_mask_path) else None,\n",
        "                        'filename': img_file,\n",
        "                        'category': category,\n",
        "                        'split': split\n",
        "                    })\n",
        "\n",
        "    return pd.DataFrame(all_data)\n",
        "\n",
        "print(\"\\nLoading Train split:\")\n",
        "train_df = load_all_categories(config['data_root'], 'Train')\n",
        "\n",
        "print(\"\\nLoading Val split:\")\n",
        "val_df = load_all_categories(config['data_root'], 'Val')\n",
        "\n",
        "print(\"\\nLoading Test split:\")\n",
        "test_df = load_all_categories(config['data_root'], 'Test')\n",
        "\n",
        "print(f\"Train samples: {len(train_df)}\")\n",
        "print(f\"Val samples: {len(val_df)}\")\n",
        "print(f\"Test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(val_df) + len(test_df)}\")"
      ],
      "metadata": {
        "id": "90ERw7JSMkXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb6cc5b-0292-409e-f59d-584973f6ec91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading Train split:\n",
            "  COVID-19: Found 1864 images\n",
            "  Non-COVID: Found 932 images\n",
            "  Normal: Found 932 images\n",
            "\n",
            "Loading Val split:\n",
            "  COVID-19: Found 466 images\n",
            "  Non-COVID: Found 233 images\n",
            "  Normal: Found 233 images\n",
            "\n",
            "Loading Test split:\n",
            "  COVID-19: Found 583 images\n",
            "  Non-COVID: Found 292 images\n",
            "  Normal: Found 291 images\n",
            "Train samples: 3728\n",
            "Val samples: 932\n",
            "Test samples: 1166\n",
            "Total samples: 5826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Weights"
      ],
      "metadata": {
        "id": "pKE2gHddJiX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_weights(df):\n",
        "    total_positive = 0\n",
        "    total_negative = 0\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Calculating class weights\"):\n",
        "        mask = cv2.imread(row['infection_mask_path'], cv2.IMREAD_GRAYSCALE)\n",
        "        binary_mask = (mask > 127).astype(np.uint8)\n",
        "\n",
        "        total_positive += np.sum(binary_mask)\n",
        "        total_negative += np.sum(1 - binary_mask)\n",
        "\n",
        "    pos_weight = total_negative / (total_positive + 1e-6)\n",
        "\n",
        "    print(f\"\\nClass distribution:\")\n",
        "    print(f\"  Positive pixels: {total_positive}\")\n",
        "    print(f\"  Negative pixels: {total_negative}\")\n",
        "    print(f\"  Positive weight: {pos_weight:.4f}\")\n",
        "\n",
        "    return pos_weight\n",
        "\n",
        "pos_weight = calculate_class_weights(train_df)"
      ],
      "metadata": {
        "id": "7DVieTKpMs0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2028ecf-6429-46d7-a58d-f4381b59f679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating class weights: 100%|██████████| 3728/3728 [00:03<00:00, 1066.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class distribution:\n",
            "  Positive pixels: 17043669\n",
            "  Negative pixels: 227274539\n",
            "  Positive weight: 13.3348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Loss"
      ],
      "metadata": {
        "id": "QeUF0A-AJkbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.contiguous().view(-1)\n",
        "        target = target.contiguous().view(-1)\n",
        "\n",
        "        intersection = (pred * target).sum()\n",
        "        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
        "\n",
        "        return 1 - dice\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
        "        super(BCEDiceLoss, self).__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.dice = DiceLoss()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.dice_weight = dice_weight\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        bce_loss = self.bce(pred, target)\n",
        "        pred_sigmoid = torch.sigmoid(pred)\n",
        "        dice_loss = self.dice(pred_sigmoid, target)\n",
        "\n",
        "        return self.bce_weight * bce_loss + self.dice_weight * dice_loss\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(pred, target, reduction='none')\n",
        "        pt = torch.exp(-bce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
        "\n",
        "        return focal_loss.mean()\n",
        "\n",
        "class WeightedBCEDiceLoss(nn.Module):\n",
        "    def __init__(self, bce_weight=0.5, dice_weight=0.5, pos_weight=1.0):\n",
        "        super(WeightedBCEDiceLoss, self).__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]))\n",
        "        self.dice = DiceLoss()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.dice_weight = dice_weight\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        bce_loss = self.bce(pred, target)\n",
        "        pred_sigmoid = torch.sigmoid(pred)\n",
        "        dice_loss = self.dice(pred_sigmoid, target)\n",
        "\n",
        "        return self.bce_weight * bce_loss + self.dice_weight * dice_loss\n",
        "\n",
        "\n",
        "def get_loss_function(loss_name, pos_weight = 1.0):\n",
        "    if loss_name == 'dice':\n",
        "        return DiceLoss()\n",
        "    elif loss_name == 'bce_dice':\n",
        "        return WeightedBCEDiceLoss(pos_weight=pos_weight)\n",
        "    elif loss_name == 'focal':\n",
        "        return FocalLoss()\n",
        "    elif loss_name == 'bce':\n",
        "        return nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]))\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown loss function: {loss_name}\")"
      ],
      "metadata": {
        "id": "peD9G4MpOn_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Metrics"
      ],
      "metadata": {
        "id": "p6_5z5HGJn5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(pred, target, smooth=1e-6):\n",
        "    pred = pred.contiguous().view(-1)\n",
        "    target = target.contiguous().view(-1)\n",
        "\n",
        "    intersection = (pred * target).sum()\n",
        "    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
        "\n",
        "    return dice.item()\n",
        "\n",
        "def iou_score(pred, target, smooth=1e-6):\n",
        "    pred = pred.contiguous().view(-1)\n",
        "    target = target.contiguous().view(-1)\n",
        "\n",
        "    intersection = (pred * target).sum()\n",
        "    union = pred.sum() + target.sum() - intersection\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return iou.item()\n",
        "\n",
        "def pixel_accuracy(pred, target):\n",
        "    pred = pred.contiguous().view(-1)\n",
        "    target = target.contiguous().view(-1)\n",
        "\n",
        "    correct = (pred == target).sum()\n",
        "    total = target.numel()\n",
        "\n",
        "    return (correct.float() / total).item()\n",
        "\n",
        "def calculate_metrics(pred, target, threshold=0.5):\n",
        "    pred_binary = (pred > threshold).float()\n",
        "    target_binary = target.float()\n",
        "\n",
        "    dice = dice_coefficient(pred_binary, target_binary)\n",
        "    iou = iou_score(pred_binary, target_binary)\n",
        "    accuracy = pixel_accuracy(pred_binary, target_binary)\n",
        "\n",
        "    pred_np = pred_binary.cpu().numpy().flatten()\n",
        "    target_np = target_binary.cpu().numpy().flatten()\n",
        "\n",
        "    precision = precision_score(target_np, pred_np, zero_division=0)\n",
        "    recall = recall_score(target_np, pred_np, zero_division=0)\n",
        "    f1 = f1_score(target_np, pred_np, zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'dice': dice,\n",
        "        'iou': iou,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "-qa2d-pHOPzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Architechture"
      ],
      "metadata": {
        "id": "Ad-uSI2wJrQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(architecture, encoder_name, encoder_weights='imagenet'):\n",
        "    if architecture == 'Unet':\n",
        "        model = smp.Unet(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=1,\n",
        "            classes=1,\n",
        "            activation=None\n",
        "        )\n",
        "    elif architecture == 'UnetPlusPlus':\n",
        "        model = smp.UnetPlusPlus(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=1,\n",
        "            classes=1,\n",
        "            activation=None\n",
        "        )\n",
        "    elif architecture == 'FPN':\n",
        "        model = smp.FPN(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=1,\n",
        "            classes=1,\n",
        "            activation=None\n",
        "        )\n",
        "    elif architecture == 'DeepLabV3Plus':\n",
        "        model = smp.DeepLabV3Plus(\n",
        "            encoder_name=encoder_name,\n",
        "            encoder_weights=encoder_weights,\n",
        "            in_channels=1,\n",
        "            classes=1,\n",
        "            activation=None\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown architecture: {architecture}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "kKmUdkOMOydA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Augmentation"
      ],
      "metadata": {
        "id": "VJmT9wFXJuz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_transforms(image_size):\n",
        "    return A.Compose([\n",
        "        A.Resize(image_size, image_size),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.3),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.3),\n",
        "        A.GaussNoise(var_limit=(5.0, 15.0), p=0.2),\n",
        "        A.Normalize(mean=[0.485], std=[0.229]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_val_transforms(image_size):\n",
        "    return A.Compose([\n",
        "        A.Resize(image_size, image_size),\n",
        "        A.Normalize(mean=[0.485], std=[0.229]),\n",
        "        ToTensorV2(),\n",
        "    ])"
      ],
      "metadata": {
        "id": "YaqshMcxSwtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None, debug=False):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.debug = debug\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        image = cv2.imread(row['image_path'], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        mask = cv2.imread(row['infection_mask_path'], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.debug and idx == 0:\n",
        "            print(f\"Debug - Before processing:\")\n",
        "            print(f\"  Image shape: {image.shape}, range: [{image.min()}, {image.max()}]\")\n",
        "            print(f\"  Mask shape: {mask.shape}, range: [{mask.min()}, {mask.max()}]\")\n",
        "            print(f\"  Infection pixels: {np.sum(mask > 127)}\")\n",
        "\n",
        "        image = np.expand_dims(image, axis=-1) # Expand dimensions for grayscale\n",
        "\n",
        "        # Binarize mask: 0 or 1\n",
        "        mask = (mask > 127).astype(np.float32)\n",
        "\n",
        "        if self.debug and idx == 0:\n",
        "            print(f\"Debug - After binarization:\")\n",
        "            print(f\"  Mask unique values: {np.unique(mask)}\")\n",
        "            print(f\"  Positive pixels: {np.sum(mask > 0.5)}\")\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed['image']\n",
        "            mask = transformed['mask']\n",
        "\n",
        "        # Ensure mask has correct shape [1, H, W]\n",
        "        if len(mask.shape) == 2:\n",
        "            mask = mask.unsqueeze(0)\n",
        "\n",
        "        if self.debug and idx == 0:\n",
        "            print(f\"Debug - After transform:\")\n",
        "            print(f\"  Image shape: {image.shape}\")\n",
        "            print(f\"  Mask shape: {mask.shape}\")\n",
        "            print(f\"  Mask unique values: {torch.unique(mask)}\")\n",
        "\n",
        "        return {\n",
        "            'image': image,\n",
        "            'mask': mask,\n",
        "            'filename': row['filename']\n",
        "        }\n",
        "\n",
        "test_dataset = COVID19Dataset(train_df[:1], transform=get_val_transforms(256), debug=True)\n",
        "sample = test_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kjtPWY8SiLB",
        "outputId": "3aa4a54a-3a94-4e90-9c39-aecfd7fdddc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debug - Before processing:\n",
            "  Image shape: (256, 256), range: [0, 255]\n",
            "  Mask shape: (256, 256), range: [0, 255]\n",
            "  Infection pixels: 9040\n",
            "Debug - After binarization:\n",
            "  Mask unique values: [0. 1.]\n",
            "  Positive pixels: 9040\n",
            "Debug - After transform:\n",
            "  Image shape: torch.Size([1, 256, 256])\n",
            "  Mask shape: torch.Size([1, 256, 256])\n",
            "  Mask unique values: tensor([0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = COVID19Dataset(train_df, transform=get_train_transforms(config['image_size']))\n",
        "val_dataset = COVID19Dataset(val_df, transform=get_val_transforms(config['image_size']))\n",
        "test_dataset = COVID19Dataset(test_df, transform=get_val_transforms(config['image_size']))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "model = get_model(config['architecture'], config['encoder_name'], config['encoder_weights'])\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = get_loss_function(config['loss_function'], pos_weight=pos_weight)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['num_epochs'])"
      ],
      "metadata": {
        "id": "3kMtM3pIMxVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd796a3e-26f9-4961-bc79-6fbc42863639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 466\n",
            "Val batches: 117\n",
            "Test batches: 146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_metrics = {\n",
        "        'dice': [],\n",
        "        'iou': [],\n",
        "        'accuracy': [],\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'f1': []\n",
        "    }\n",
        "\n",
        "    pbar = tqdm(dataloader, desc='Training')\n",
        "    for batch in pbar:\n",
        "        images = batch['image'].to(device)\n",
        "        masks = batch['mask'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_sigmoid = torch.sigmoid(outputs)\n",
        "            metrics = calculate_metrics(pred_sigmoid, masks)\n",
        "            for key in all_metrics.keys():\n",
        "                all_metrics[key].append(metrics[key])\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'dice': f'{metrics[\"dice\"]:.4f}'\n",
        "        })\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_metrics = {key: np.mean(values) for key, values in all_metrics.items()}\n",
        "    avg_metrics['loss'] = avg_loss\n",
        "\n",
        "    return avg_metrics"
      ],
      "metadata": {
        "id": "afglJGa0O8Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import ndimage\n",
        "\n",
        "def post_process_mask(pred_mask, min_size=100):\n",
        "    labeled_mask, num_features = ndimage.label(pred_mask)\n",
        "\n",
        "    if num_features == 0:\n",
        "        return pred_mask\n",
        "\n",
        "    component_sizes = ndimage.sum(pred_mask, labeled_mask, range(num_features + 1))\n",
        "\n",
        "    mask_size_filter = component_sizes >= min_size\n",
        "    mask_size_filter[0] = 0  # Background\n",
        "\n",
        "    cleaned_mask = mask_size_filter[labeled_mask]\n",
        "\n",
        "    # Morphological closing to fill small holes\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    cleaned_mask = cv2.morphologyEx(cleaned_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    return cleaned_mask\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_metrics = {\n",
        "        'dice': [],\n",
        "        'dice_postprocess': [],\n",
        "        'iou': [],\n",
        "        'accuracy': [],\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'f1': []\n",
        "    }\n",
        "\n",
        "    pbar = tqdm(dataloader, desc='Validation')\n",
        "    with torch.no_grad():\n",
        "        for batch in pbar:\n",
        "            images = batch['image'].to(device)\n",
        "            masks = batch['mask'].to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            pred_sigmoid = torch.sigmoid(outputs)\n",
        "\n",
        "            # Metrics without post-processing\n",
        "            metrics = calculate_metrics(pred_sigmoid, masks)\n",
        "            for key in ['dice', 'iou', 'accuracy', 'precision', 'recall', 'f1']:\n",
        "                all_metrics[key].append(metrics[key])\n",
        "\n",
        "            # Metrics with post-processing\n",
        "            pred_binary = (pred_sigmoid > 0.5).cpu().numpy()\n",
        "            for i in range(pred_binary.shape[0]):\n",
        "                pred_postprocess = post_process_mask(pred_binary[i, 0])\n",
        "                pred_postprocess_tensor = torch.from_numpy(pred_postprocess).float().unsqueeze(0).to(device)\n",
        "\n",
        "                dice_pp = dice_coefficient(pred_postprocess_tensor, masks[i])\n",
        "                all_metrics['dice_postprocess'].append(dice_pp)\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'dice': f'{metrics[\"dice\"]:.4f}'\n",
        "            })\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_metrics = {key: np.mean(values) for key, values in all_metrics.items()}\n",
        "    avg_metrics['loss'] = avg_loss\n",
        "\n",
        "    return avg_metrics"
      ],
      "metadata": {
        "id": "KjEv8jCRPBRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Train + Validation"
      ],
      "metadata": {
        "id": "lmi0KhrmJ4kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = load_all_categories(config['data_root'], 'Train')\n",
        "val_df = load_all_categories(config['data_root'], 'Val')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "print(f\"Train samples: {len(train_df)}\")\n",
        "print(f\"Val samples: {len(val_df)}\")\n",
        "\n",
        "pos_weight = calculate_class_weights(train_df)\n",
        "\n",
        "train_dataset = COVID19Dataset(train_df, transform=get_train_transforms(config['image_size']))\n",
        "val_dataset = COVID19Dataset(val_df, transform=get_val_transforms(config['image_size']))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "model = get_model(config['architecture'], config['encoder_name'], config['encoder_weights'])\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = get_loss_function(config['loss_function'], pos_weight=pos_weight)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['num_epochs'])\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    print(f\"Resuming from epoch {start_epoch + 1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scrWHXoKHqzr",
        "outputId": "a4e1478f-2661-4cbd-db0e-e73f93ae473b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COVID-19: Found 1864 images\n",
            "Non-COVID: Found 932 images\n",
            "Normal: Found 932 images\n",
            "COVID-19: Found 466 images\n",
            "Non-COVID: Found 233 images\n",
            "Normal: Found 233 images\n",
            "Using device: cuda\n",
            "Train samples: 3728\n",
            "Val samples: 932\n",
            "Calculating class weights: 100%|██████████| 3728/3728 [00:02<00:00, 1263.23it/s]\n",
            "Class distribution:\n",
            "Positive pixels: 17043669\n",
            "Negative pixels: 227274539\n",
            "Positive weight: 13.3348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patience_counter = 0\n",
        "best_epoch = start_epoch\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, config['num_epochs']):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{config['num_epochs']}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Train\n",
        "    train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "    # Validate\n",
        "    val_metrics = validate_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "    # Step scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"\\nTrain - Loss: {train_metrics['loss']:.4f}, Dice: {train_metrics['dice']:.4f}, IoU: {train_metrics['iou']:.4f}\")\n",
        "    print(f\"Val   - Loss: {val_metrics['loss']:.4f}, Dice: {val_metrics['dice']:.4f}, IoU: {val_metrics['iou']:.4f}\")\n",
        "\n",
        "\n",
        "    # Save best model\n",
        "    if val_metrics['dice'] > best_dice:\n",
        "        best_dice = val_metrics['dice']\n",
        "        best_epoch = epoch + 1\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_dice': best_dice,\n",
        "            'config': config\n",
        "        }, '/content/best_model.pth')\n",
        "\n",
        "        print(f\"\\n✓ Saved best model with Dice: {best_dice:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    # Early stopping\n",
        "    if patience_counter >= config['patience']:\n",
        "        print(f\"\\n⚠ Early stopping triggered after {epoch + 1} epochs\")\n",
        "        print(f\"Best Dice: {best_dice:.4f} at epoch {best_epoch}\")\n",
        "        break\n",
        "print(f\"Best Validation Dice: {best_dice:.4f} at epoch {best_epoch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTbO1A40IASc",
        "outputId": "731d337a-a455-4781-8e69-6b182e85be3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30\n",
            "----------------------------------------------------------------------\n",
            "Training: 100%|██████████| 466/466 [02:55<00:00,  2.65it/s, loss=0.3025, dice=0.6788]\n",
            "Validation: 100%|██████████| 117/117 [00:21<00:00,  5.45it/s, loss=0.5000, dice=1.0000]\n",
            "Train - Loss: 0.1779, Dice: 0.8183, IoU: 0.7050\n",
            "Val   - Loss: 0.3982, Dice: 0.8952, IoU: 0.8390\n",
            "TRAINING COMPLETE\n",
            "Best Validation Dice: 0.9032 at epoch 26\n",
            "Run summary:\n",
            "epoch\t30\n",
            "learning_rate\t0\n",
            "train_accuracy\t0.97321\n",
            "train_dice\t0.8183\n",
            "train_f1\t0.8183\n",
            "train_iou\t0.70495\n",
            "train_loss\t0.17789\n",
            "train_precision\t0.72724\n",
            "train_recall\t0.95723\n",
            "val_accuracy\t0.97686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Testing"
      ],
      "metadata": {
        "id": "tLcpVkGzKCGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
        "checkpoint = torch.load('/content/best_model.pth', weights_only=False)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "all_test_metrics = { # Evaluate on test set\n",
        "    'dice': [],\n",
        "    'iou': [],\n",
        "    'accuracy': [],\n",
        "    'precision': [],\n",
        "    'recall': [],\n",
        "    'f1': []\n",
        "}\n",
        "\n",
        "print(\"\\nRunning inference on test set\")\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc='Test Inference'):\n",
        "        images = batch['image'].to(device)\n",
        "        masks = batch['mask'].to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        pred_sigmoid = torch.sigmoid(outputs)\n",
        "\n",
        "        metrics = calculate_metrics(pred_sigmoid, masks)\n",
        "        for key in all_test_metrics.keys():\n",
        "            all_test_metrics[key].append(metrics[key])\n",
        "\n",
        "avg_test_metrics = {key: np.mean(values) for key, values in all_test_metrics.items()}\n",
        "\n",
        "print(\"TEST SET RESULTS\")\n",
        "print(f\"Dice Coefficient: {avg_test_metrics['dice']:.4f}\")\n",
        "print(f\"IoU Score:        {avg_test_metrics['iou']:.4f}\")\n",
        "print(f\"Pixel Accuracy:   {avg_test_metrics['accuracy']:.4f}\")\n",
        "print(f\"Precision:        {avg_test_metrics['precision']:.4f}\")\n",
        "print(f\"Recall:           {avg_test_metrics['recall']:.4f}\")\n",
        "print(f\"F1 Score:         {avg_test_metrics['f1']:.4f}\")"
      ],
      "metadata": {
        "id": "EEpNeI-qNGmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25421734-577d-4889-bff9-c36712d5935f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference on test set\n",
            "Test Inference:   0%|          | 0/1 [00:00<?, ?it/s]Debug - Before processing:\n",
            " Image shape: (256, 256), range: [0, 255]\n",
            " Mask shape: (256, 256), range: [0, 255]\n",
            " Infection pixels: 9040\n",
            "Debug - After binarization:\n",
            " Mask unique values: [0. 1.]\n",
            " Positive pixels: 9040\n",
            "Debug - After transform:\n",
            " Image shape: torch.Size([1, 256, 256])\n",
            " Mask shape: torch.Size([1, 256, 256])\n",
            " Mask unique values: tensor([0., 1.])\n",
            "Test Inference: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]TEST SET RESULTS\n",
            "Dice Coefficient: 0.9218\n",
            "IoU Score:        0.8550\n",
            "Pixel Accuracy:   0.9768\n",
            "Precision:        0.8610\n",
            "Recall:           0.9918\n",
            "F1 Score:         0.9218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Visualize"
      ],
      "metadata": {
        "id": "kyNyPQpDKH9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some test predictions\n",
        "num_samples = min(8, len(test_dataset))\n",
        "fig, axes = plt.subplots(num_samples, 3, figsize=(12, num_samples * 4))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i in range(num_samples):\n",
        "        sample = test_dataset[i]\n",
        "        image = sample['image'].unsqueeze(0).to(device)\n",
        "        true_mask = sample['mask'].squeeze().cpu().numpy()\n",
        "\n",
        "        output = model(image)\n",
        "        pred_mask = torch.sigmoid(output).squeeze().cpu().numpy()\n",
        "        pred_mask_binary = (pred_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "        img_np = sample['image'].squeeze().cpu().numpy()\n",
        "\n",
        "        # Denormalize image for visualization\n",
        "        img_denorm = img_np * 0.229 + 0.485\n",
        "\n",
        "        axes[i, 0].imshow(img_denorm, cmap='gray')\n",
        "        axes[i, 0].set_title('Input Image')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(true_mask, cmap='gray')\n",
        "        axes[i, 1].set_title('Ground Truth')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        axes[i, 2].imshow(img_denorm, cmap='gray')\n",
        "        axes[i, 2].imshow(pred_mask_binary, cmap='Reds', alpha=0.5)\n",
        "\n",
        "        # Calculate Dice for this sample\n",
        "        dice = dice_coefficient(\n",
        "            torch.from_numpy(pred_mask_binary).float(),\n",
        "            torch.from_numpy(true_mask).float()\n",
        "        )\n",
        "        axes[i, 2].set_title(f'Prediction (Dice: {dice:.3f})')\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/test_predictions.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T9TR_8lBNU6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = {\n",
        "    'best_val_dice': best_dice,\n",
        "    'best_epoch': best_epoch,\n",
        "    'test_dice': avg_test_metrics['dice'],\n",
        "    'test_iou': avg_test_metrics['iou'],\n",
        "    'test_f1': avg_test_metrics['f1'],\n",
        "    'config': config\n",
        "}\n",
        "print(f\"Best Val Dice:  {best_dice:.4f}\")\n",
        "print(f\"Test Dice:      {avg_test_metrics['dice']:.4f}\")\n",
        "print(f\"Test IoU:       {avg_test_metrics['iou']:.4f}\")"
      ],
      "metadata": {
        "id": "aBWKFnfBNb2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}